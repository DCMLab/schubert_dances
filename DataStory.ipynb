{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Analyzing a Corpus of Sheet Music<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Characterizing-a-data-set-of-435-short-piano-dances-by-Franz-Schubert\" data-toc-modified-id=\"Characterizing-a-data-set-of-435-short-piano-dances-by-Franz-Schubert-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Characterizing a data set of 435 short piano dances by Franz Schubert</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Authors\" data-toc-modified-id=\"The-Authors-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>The Authors</a></span></li><li><span><a href=\"#Abstract\" data-toc-modified-id=\"Abstract-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Abstract</a></span></li><li><span><a href=\"#The-data-set\" data-toc-modified-id=\"The-data-set-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>The data set</a></span><ul class=\"toc-item\"><li><span><a href=\"#Historical-Background:-The-Viennese-dance-floor\" data-toc-modified-id=\"Historical-Background:-The-Viennese-dance-floor-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Historical Background: The Viennese dance floor</a></span></li><li><span><a href=\"#Format\" data-toc-modified-id=\"Format-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Format</a></span></li><li><span><a href=\"#Structure-of-the-data-set\" data-toc-modified-id=\"Structure-of-the-data-set-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Structure of the data set</a></span></li><li><span><a href=\"#The-Labels:-Dance-types\" data-toc-modified-id=\"The-Labels:-Dance-types-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>The Labels: Dance types</a></span></li><li><span><a href=\"#Handling-the-data\" data-toc-modified-id=\"Handling-the-data-1.3.5\"><span class=\"toc-item-num\">1.3.5&nbsp;&nbsp;</span>Handling the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hints-for-music-notation-agnostics\" data-toc-modified-id=\"Hints-for-music-notation-agnostics-1.3.5.1\"><span class=\"toc-item-num\">1.3.5.1&nbsp;&nbsp;</span>Hints for music notation agnostics</a></span></li><li><span><a href=\"#Parsing-XML-sheet-music-to-obtain-the-working-representation\" data-toc-modified-id=\"Parsing-XML-sheet-music-to-obtain-the-working-representation-1.3.5.2\"><span class=\"toc-item-num\">1.3.5.2&nbsp;&nbsp;</span>Parsing XML sheet music to obtain the working representation</a></span></li><li><span><a href=\"#Note-list-features\" data-toc-modified-id=\"Note-list-features-1.3.5.3\"><span class=\"toc-item-num\">1.3.5.3&nbsp;&nbsp;</span>Note list features</a></span></li><li><span><a href=\"#Measure-list-features\" data-toc-modified-id=\"Measure-list-features-1.3.5.4\"><span class=\"toc-item-num\">1.3.5.4&nbsp;&nbsp;</span>Measure list features</a></span></li><li><span><a href=\"#Feature-expansion\" data-toc-modified-id=\"Feature-expansion-1.3.5.5\"><span class=\"toc-item-num\">1.3.5.5&nbsp;&nbsp;</span>Feature expansion</a></span></li><li><span><a href=\"#Feature-normalization\" data-toc-modified-id=\"Feature-normalization-1.3.5.6\"><span class=\"toc-item-num\">1.3.5.6&nbsp;&nbsp;</span>Feature normalization</a></span></li></ul></li></ul></li><li><span><a href=\"#Research-questions-and-hypotheses\" data-toc-modified-id=\"Research-questions-and-hypotheses-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Research questions and hypotheses</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recurring-Patterns-(JH-&amp;-SR)\" data-toc-modified-id=\"Recurring-Patterns-(JH-&amp;-SR)-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Recurring Patterns (JH &amp; SR)</a></span></li><li><span><a href=\"#Dance-Type-Classification-(GC-&amp;-JR)\" data-toc-modified-id=\"Dance-Type-Classification-(GC-&amp;-JR)-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Dance Type Classification (GC &amp; JR)</a></span></li></ul></li></ul></li><li><span><a href=\"#Recurring-patterns\" data-toc-modified-id=\"Recurring-patterns-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Recurring patterns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Most-common-rhythms\" data-toc-modified-id=\"Most-common-rhythms-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Most common rhythms</a></span><ul class=\"toc-item\"><li><span><a href=\"#Most-frequent-patterns-in-double-meter-(2/4)\" data-toc-modified-id=\"Most-frequent-patterns-in-double-meter-(2/4)-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Most frequent patterns in double meter (2/4)</a></span></li><li><span><a href=\"#Most-frequent-rhythms-in-triple-meter-(3/4)\" data-toc-modified-id=\"Most-frequent-rhythms-in-triple-meter-(3/4)-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Most frequent rhythms in triple meter (3/4)</a></span></li><li><span><a href=\"#Most-stereotypical-pieces-in-double-meter\" data-toc-modified-id=\"Most-stereotypical-pieces-in-double-meter-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Most stereotypical pieces in double meter</a></span></li><li><span><a href=\"#Most-stereotypical-pieces-in-triple-meter\" data-toc-modified-id=\"Most-stereotypical-pieces-in-triple-meter-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Most stereotypical pieces in triple meter</a></span></li></ul></li><li><span><a href=\"#Repeating-pattern-detection-with-auto-correlation\" data-toc-modified-id=\"Repeating-pattern-detection-with-auto-correlation-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Repeating pattern detection with auto-correlation</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-to-identify-a-repeating-part-from-a-new-part?\" data-toc-modified-id=\"How-to-identify-a-repeating-part-from-a-new-part?-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>How to identify a repeating part from a new part?</a></span></li><li><span><a href=\"#Definition-of-an-auto-correlation-for-a-musical-piece\" data-toc-modified-id=\"Definition-of-an-auto-correlation-for-a-musical-piece-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Definition of an auto-correlation for a musical piece</a></span></li><li><span><a href=\"#Using-auto-correlation-for-initial-section-detection\" data-toc-modified-id=\"Using-auto-correlation-for-initial-section-detection-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Using auto-correlation for initial section detection</a></span></li><li><span><a href=\"#From-initial-section-detection-to-dance-structure\" data-toc-modified-id=\"From-initial-section-detection-to-dance-structure-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>From initial section detection to dance structure</a></span></li></ul></li></ul></li><li><span><a href=\"#Classifying-dance-types\" data-toc-modified-id=\"Classifying-dance-types-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Classifying dance types</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.2-Features\" data-toc-modified-id=\"2.2-Features-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>2.2 Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Complexity\" data-toc-modified-id=\"Complexity-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Complexity</a></span></li><li><span><a href=\"#Key\" data-toc-modified-id=\"Key-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Key</a></span><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-3.1.2.1\"><span class=\"toc-item-num\">3.1.2.1&nbsp;&nbsp;</span>Intro</a></span></li><li><span><a href=\"#Methodology\" data-toc-modified-id=\"Methodology-3.1.2.2\"><span class=\"toc-item-num\">3.1.2.2&nbsp;&nbsp;</span>Methodology</a></span></li><li><span><a href=\"#Tracking-key\" data-toc-modified-id=\"Tracking-key-3.1.2.3\"><span class=\"toc-item-num\">3.1.2.3&nbsp;&nbsp;</span>Tracking key</a></span></li><li><span><a href=\"#Variety\" data-toc-modified-id=\"Variety-3.1.2.4\"><span class=\"toc-item-num\">3.1.2.4&nbsp;&nbsp;</span>Variety</a></span></li><li><span><a href=\"#Mode-identification\" data-toc-modified-id=\"Mode-identification-3.1.2.5\"><span class=\"toc-item-num\">3.1.2.5&nbsp;&nbsp;</span>Mode identification</a></span></li></ul></li><li><span><a href=\"#Rhythmic-patterns\" data-toc-modified-id=\"Rhythmic-patterns-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Rhythmic patterns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Event-density\" data-toc-modified-id=\"Event-density-3.1.3.1\"><span class=\"toc-item-num\">3.1.3.1&nbsp;&nbsp;</span>Event density</a></span></li></ul></li><li><span><a href=\"#Characteristic-intervals\" data-toc-modified-id=\"Characteristic-intervals-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Characteristic intervals</a></span></li></ul></li><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Clustering</a></span></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Classification</a></span></li><li><span><a href=\"#Can-you-do-better?\" data-toc-modified-id=\"Can-you-do-better?-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Can you do better?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VIEW THIS NOTEBOOK ON NBVIEWER:** https://nbviewer.jupyter.org/github/DCMLab/schubert_dances/blob/master/DataStory.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html \n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "  img {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jh, os\n",
    "import pandas as pd\n",
    "from IPython.display import display_html \n",
    "\n",
    "def display_side_by_side(title_df_dict):\n",
    "    \"\"\"Pass a {'title': DataFrame} dict.\"\"\"\n",
    "    stylers = [df.style.set_table_attributes(\"style='display:inline'\").set_caption(title)._repr_html_() for title, df in title_df_dict.items()]\n",
    "    display_html(''.join(stylers), raw=True)\n",
    "\n",
    "data_ms3 = 'data/MuseScore_3'\n",
    "data_tsv = 'data/tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing a data set of 435 short piano dances by Franz Schubert\n",
    "\n",
    "## The Authors\n",
    "\n",
    "| initials | name               |\n",
    "|----------|--------------------|\n",
    "| GC       | Gabriele Cecchetti |\n",
    "| JH       | Johannes Hentschel |\n",
    "| JR       | Johannes Rüther    |\n",
    "| SR       | Sébastien Rouault  |\n",
    "\n",
    "## Abstract\n",
    "Everybody has an emotional access to music, which in turn transports listeners into specific moods, atmospheres and settings. This intuitive understanding of musical pieces is grounded in structural elements such as melodic motives and rhythms, with their variations or repetitions. Our project aims at gaining an objective insight into how these patterns engender different shades of musical engagement. Specifically, we will investigate the structure and composition of Franz Schubert's \"dances\", a large set of 435 piano pieces classified in seven different types according to their times’ conventions. The conventionality of these short and catchy pieces makes them an ideal testing ground for computer-assisted analysis, but also makes them highly representative of the taste of early-nineteenth-century listeners. With our statistical investigation we hope to open a window onto this past: what did listeners expect of appealing dance-like music, and did different dance types correspond to different musical features or just to different social perspectives on the same musical features?\n",
    "\n",
    "\n",
    "## The data set\n",
    "\n",
    "In the time between (xxxx-yyyy) the composer Franz Schubert composed ... **TODO: short historical background**\n",
    "\n",
    "### Historical Background: The Viennese dance floor\n",
    "\n",
    "The “queen of all dances” (Feldtenstein, 1767) was undoubtedly the French **Menuet**. As most dance forms of the classical repertoire, the menuet originated as a transfiguration of folk tunes into the stereotyped taste of nobility and courts, and in this form it was then exported throughout Europe. Traditionally, each menuet would be coupled with a contrasting dance, the **Trio**: hard to characterise collectively, trios were individually crafted to provide variety by conveying a different character from the related menuet, and were generally more explicit in emulating the rural origins of the dance.\n",
    " \n",
    "Closer to their rural origins, both the **Cotillon** and the **Ecossaise** are country dances and both French, the latter though being inspired by the rhythms of the Scottish folk tunes. The **Galopp** was also a fast-paced dance eventually turning into the - nowdays better known - Polka. \n",
    "\n",
    "Of strictly German origin are the **Ländler** and the **Walzer**. The former was characterised by a variety of body motions interrupted by clapping and feet stamping, evoking the scenery of countryside paesant dances. On the contrary, the Walzer was a fast and smooth spinning dance that became explosively popular because of its intrinsic sensuality, to the point that it was formally banned by the authorities several times: \"In this dance, everything is circle-shaped and whirling movement, everything designed to provoke giddiness and seduce the senses.\" (Vieth, 1794). \n",
    "\n",
    "The term **Deutscher** Tanz, literally \"German dance\", was used in association with both the Walzer and the Ländler, and it is unclear whether it would also identify a dance type of its own right: in a few instances, Schubert himself happened to label the same dances as Ländler or Deutscher. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[To know more: Oxford Handbook of Topic Theory]\n",
    "\n",
    "\n",
    "### Format\n",
    "\n",
    "The dataset consists of the 435 music scores in the XML format of the open source notation software [MuseScore 3](https://musescore.org/en/download) and has been compiled for this project by GC & JH using funds of [EPFL's Digital and Cognitive Musicology Lab (DCML)](https://dcml.epfl.ch/).\n",
    "\n",
    "### Structure of the data set\n",
    "\n",
    "The dances are separated into 53 separate work groups identified by their number in the [Deutsch Catalogue of Schubert's works](https://imslp.org/wiki/List_of_works_by_Franz_Schubert). This division is reflected in the data set's folder structure. The [file list](https://github.com/DCMLab/schubert_dances/blob/master/data/MuseScore_3/merged_ids.tsv) contains the overview of all MuseScore files and contains the following columns:\n",
    "* **id**: Identifier of every piece as assigned by the music theorist Yosef Goldenberg of the Jerusalem Academy of Music and Dance\n",
    "* **D**: Deutsch number of the corresponding work group\n",
    "* **no**: piece's number within the work group\n",
    "* **dance**: which of the eight dance types has been attributed by the composer (**labels**)\n",
    "* **path**: relative path to the file\n",
    "\n",
    "### The Labels: Dance types\n",
    "\n",
    "The titles of the different dances convey which type they were attributed to by Schubert. We consider these attributions as labels enabling us to group the data set and try to characterize the different groups. The distribution over the different dance types is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = pd.read_csv(os.path.join(data_ms3, 'merged_ids.tsv'), sep='\\t', index_col=0)\n",
    "pd.DataFrame(file_list.dance.replace(r'.*trio.*', 'trio', regex=True).value_counts()).rename(columns={'dance': 'count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the data\n",
    "\n",
    "This section elicits how we transformed the scores into our working representation, namely one note list and one measure list for the entire corpus.\n",
    "\n",
    "#### Hints for music notation agnostics\n",
    "This section briefly explains some of the main elements that music scores contain. Please compare the explanations with the example score below.\n",
    ">The words '**measure**' and '**bar**' can be used interchangeably. Measures are separated by vertical bar lines designating music chunks of equal length. They also give information about the temporal hierarchy of the notes, with the ones directly after the bar line generally being the most accented.\n",
    "\n",
    ">Note that MuseScore XML files contain one \\<Measure\\> node for every bar line and that we address these units with running numbers starting at zero which we call **measure counts (mc)**. The **measure numbers (mn)**, however, are those that are displayed/printed in the score. Since, say, a measure of length 3/4 (see `time signature`) can be split into two measures with irregular length for musical and notational conventions, measure numbers frequently span multiple measure counts and had to be computed by the parser following the usual conventions.\n",
    "\n",
    ">A **staff** (pl. 'staves') is a set of usually five horizontal lines where the positioning of note heads on or between lines determines their pitch, i.e. their vertical position in terms of note name and octave.\n",
    "\n",
    ">A **clef** determines which line represents which pitch.\n",
    "\n",
    ">A **key signature** (`KeySig`) further specifies the exact pitches and reveals information as to which `key` the piece is in. A key could be defined as a hierarchy between the occurring pitches. In the example figure above, the `KeySig` of 5 $\\flat$ means that the key of this piece is either D$\\flat$ major or B$\\flat$ minor and that the pitches B, E, A, D, G have to be lowered throughout the piece. Lowering ($\\flat$) or raising ($\\sharp$) a pitch can be understood as playing the pitch just below or just above, often resulting on the piano in playing the neighbouring black key instead of a white key.\n",
    "\n",
    "<img src=\"report/keyboard_tpc.png\" alt=\"keyboard\" style=\"width: 600px;\"/>\n",
    "_Fig. showing one octave on a piano keyboard and the most common pitch names together with their tonal pitch class `tpc`. If you consider the leftmost C as the middle C on the piano, C4, then these keys would have the `midi` numbers 60-72._\n",
    "\n",
    ">A **time signature** (`TimeSig`) stipulates the measure length and the [metre](https://en.wikipedia.org/wiki/Metre_(music)), which is the information which onset positions ('beats') are most important. In our data set, the only time signatures are 2/4 (2 quarter notes per measure, 'double meter') and 3/4 (3 quarter notes per measure, 'triple meter').\n",
    "\n",
    ">**Dynamic** markings contain information on how loud something is to be played.\n",
    "\n",
    ">**Slurs** reveal phrasing information, meaning which parts of the music are to be thought of and played as units.\n",
    "\n",
    "#### Parsing XML sheet music to obtain the working representation\n",
    "\n",
    "![score_example](report/D977ecossaise02_example.png) \n",
    "_Fig. The first two measures of the Ecossaise D. 977, no. 2. **Left:** Representation in MuseScore 3. **Right:** Abbreviated source code of the first measure in the right hand. For explanations of the terms, refer to the section 'Hints for music notation agnostics' below._\n",
    "\n",
    "Music scores are complex graphical representations of music. Trained musicians can read music scores and use them to imagine or reproduce the symbolically encoded sounds. In order to get to a working representation we have used JH's parser to create **note list** and **measure list** dataframes. This meant turning the hierarchical structure of the music scores into feature lists. As an example, we print the 10 notes contained in the first measure above and list the features that we started off with. For technical details of the parsing, please refer to [jh.ipynb](jh.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_list = jh.read_note_list(os.path.join(data_tsv, 'note_list_complete.tsv'), index_col=[0,1,2])\n",
    "note_list.loc[424].iloc[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note list features\n",
    "    \n",
    "**MultiIndex**\n",
    "* **id**: one ID per piece for easy addressing\n",
    "* **section**: in which section of the piece a note appears (sections are determined by the parser regarding special bar lines)\n",
    "* **ix**: running number of notes in this section\n",
    "    \n",
    "**Columns**\n",
    "* **mc**: measure count (see hints below)\n",
    "* **mn**: measure number\n",
    "* **onset**: temporal position of the note relative to the previous bar line expressed in fractions of a whole note (see explanation for `duration`)\n",
    "* **duration**: duration of the note expressed in fractions of a whole note; which correctly relates to the musical note values where a quarter note has the length of 1/4 of a whole note, an eighth note 1/8 and so on\n",
    "* **gracenote**: whether or not the note is a grace note and which type; grace notes are ornamental and likely to be excluded from most automated analyses; this is the only non-numerical feature but will be mainly used as a boolean value such that `Nan = False`, i.e. 'not a grace note'.\n",
    "* **nominal_duration**: note value before applying the altering `scalar`\n",
    "* **scalar**: value encoding the alteration of the `nominal_duration` caused by [dots](https://en.wikipedia.org/wiki/Dotted_note) and [triplets (or other n-tuplets)](https://en.wikipedia.org/wiki/Tuplet)\n",
    "* **tied**: three possible values (other than NaN):\n",
    "  * `1` if the [note is tied](https://en.wikipedia.org/wiki/Tie_(music)) to the next one (meaning that the next one is not causing a new attack)\n",
    "  * `-1` if the note is being tied to by the previous note (meaning that it prolongs the previous note's duration)\n",
    "  * `0` if the note is being tied to AND is tied to the next one (i.e. `-1 + 1 = 0`)\n",
    "* **tpc**: stands for Tonal [Pitch Class](https://en.wikipedia.org/wiki/Pitch_class) and is a numerical encoding of tone names such that `C = 0`. All other names are ordered along the [line of fifths](https://en.wikipedia.org/wiki/Circle_of_fifths):\n",
    "  * descending from C: `F = -1`, `Bb = -2`, `Eb = -3` etc.\n",
    "  * ascending from C: `G = 1`, `D = 2`, `A = 3` etc.\n",
    "* **midi**: encodes which piano key needs to be pressed to produce this note, meaning that `midi` information encodes in which octave the note is sounding (unlike `tpc`) but not as which note name the note is written in the score (note that the same key on the piano is pressed to produce different note names (`tpc`s), for example the key `midi == 66` can be written in a score as F#4 (`tpc == 6`) , Gb4 (`tpc == -6`), E##4 (`tpc == 17`), Abbb4 (`tpc == -18`) etc. where 4 designates octave 4).\n",
    "* **staff**: whether a note is written in the right hand (`staff == 1`) or in the left hand (`staff == 2`)\n",
    "* **voice**: In Common Music Notation, when simultaneously sounding notes with different durations appear in the same `staff`, they have to be written in different layers. MuseScore can represent up to four different layers per `staff`, with `voice == 1` usually representing the highest. Note that this is the notational notion of the word 'voices', not the musical nor the physiological one: `voice == 1` can contain more than one simultaneous event with the same `onset` and `duration` (i.e., a chord), whereas in the musical sense, an 'upper voice' or 'melody' consists only of one note at a time and is difficult to automatically extract from a score.\n",
    "* **volta**: Some repeated sections are played with different endings the first (`volta == 1`) and the second time (`volta == 2`). These endings ('voltas') can span one or multiple measures and the measures in a second volta have the same `measure number`s as the ones in the first.\n",
    "  \n",
    "#### Measure list features\n",
    "The features of the measure list are before all those explained above in the section _Hints for music notation agnostics_. The other serve mostly our parser's internal purposes and are irrelevant to our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_list = jh.read_measure_list(os.path.join(data_tsv, 'measure_list_complete.tsv'), index_col=[0,1])\n",
    "measure_list.loc[[424]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature expansion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jh.compute_beat_column(note_list, measure_list, inplace=True)\n",
    "note_list['note_names']        = jh.tpc2name(note_list.tpc)\n",
    "note_list['octaves']           = jh.midi2octave(note_list.midi)\n",
    "note_list[['beat', 'subbeat']] = jh.split_beats(note_list.beats)\n",
    "note_list.to_csv(os.path.join(data_tsv,'note_list_expanded.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_list = jh.read_note_list(os.path.join(data_tsv,'note_list_expanded.tsv'), index_col=[0,1,2])\n",
    "note_list.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature normalization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "transposed                      = jh.transpose_to_C(note_list, measure_list)\n",
    "transposed.note_names           = jh.tpc2name(transposed.tpc)\n",
    "transposed.octaves              = jh.midi2octave(transposed.midi)\n",
    "transposed.to_csv(os.path.join(data_tsv,'transposed_schubert.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed = jh.read_note_list(os.path.join(data_tsv,'transposed_schubert.tsv'), index_col=[0,1,2])\n",
    "transposed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research questions and hypotheses\n",
    "\n",
    "### Recurring Patterns (JH & SR) \n",
    "\n",
    "**What recurring patterns and regularities make Schubert's dances so intuitively appealing and easy to grasp?** Possible levels of investigation:\n",
    "  * rhythmic patterns\n",
    "  * melodic patterns\n",
    "  * harmonic makeup\n",
    "  * formal level\n",
    "  \n",
    "### Dance Type Classification (GC & JR) \n",
    "\n",
    "**Are the different dance types musically distinguishable? Which features will a classifier use to distinguish the different dance types?** Hypothetically, these features will include:\n",
    "  * meter\n",
    "  * melodic motives and shapes\n",
    "  * musical form\n",
    "  * harmonic progressions\n",
    "  * rhythmic markup\n",
    "  * musical texture\n",
    "  * relation between the two hands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurring patterns\n",
    "\n",
    "## Most common rhythms\n",
    "\n",
    "To get a first overview of the most common rhythms appearing in Schubert's dances, we extract and count the onset patterns of every measure. We define an onset pattern as an ordered list of unique onsets. Consider for example the first measure of the _Walzer D. 924, no. 1_ \n",
    "<img src=\"report/D924walzer01_beginning.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "In the left hand, there are only three quarter notes, which corresponds to the onset pattern `[0, 1/4, 1/2]` whereas the right hand also has eight notes and the onset pattern `[0, 1/4, 3/8, 1/2, 5/8]`. The latter is also the onset pattern of the whole measure since it has the more fine-grained onset distribution and the left-hand rhythm only duplicates onsets. Since lists of fractions are unintuitive feature representations, we decided to translate them into rhythmical language by mapping all possible divisions, the **rhythmical atoms**, to syllables as they are frequently used by music pedagogues: **TODO: Correct timgi -> gimri**\n",
    "![syllables](report/syllables_lettered.png)\n",
    "\n",
    "| pattern | onset pattern                    | length |\n",
    "|---------|:---------------------------------|--------|\n",
    "| A       | [0]                              | 3/4    |\n",
    "| B       | [0]                              | 1/2    |\n",
    "| C       | [0, 3/8]                         | 1/2    |\n",
    "| D       | [0]                              | 1/4    |\n",
    "| E       | [0, 1/8]                         | 1/4    |\n",
    "| F       | [0, 1/16, 1/8, 3/16]             | 1/4    |\n",
    "| G       | [0, 3/16]                        | 1/4    |\n",
    "| H       | [0, 1/32, 1/16, 3/32, 1/8, 7/32] | 1/4    |\n",
    "| I       | [0, 1/12, 1/6]                   | 1/4    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining selection masks\n",
    "mask = (note_list.volta != 1) & (note_list.mn != 0) # filter out first voltas and pickup measures\n",
    "double_meter, triple_meter = (note_list.timesig == '2/4'), (note_list.timesig == '3/4')\n",
    "right, left = (note_list.staff == 1), (note_list.staff == 2)\n",
    "osp_triple = note_list[mask & triple_meter].groupby(['id', 'mn']).apply(jh.os_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent patterns in double meter (2/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dm_pieces = note_list[mask & double_meter]\n",
    "n_measures_per_dm_piece = dm_pieces.groupby(['id']).mn.nunique()\n",
    "osp_double = note_list[mask & double_meter].groupby(['id', 'mn']).apply(jh.os_pattern)\n",
    "osp_double_r = note_list[mask & double_meter & right].groupby(['id', 'mn']).apply(jh.os_pattern)\n",
    "osp_double_l = note_list[mask & double_meter & left].groupby(['id', 'mn']).apply(jh.os_pattern)\n",
    "df0 = jh.get_pattern_list(osp_double, n_most_frequent=15, normalize=True)\n",
    "df1 = jh.get_pattern_list(osp_double_r, n_most_frequent=15, normalize=True)\n",
    "df2 = jh.get_pattern_list(osp_double_l, n_most_frequent=15, normalize=True)\n",
    "display_side_by_side({'overall': df0,'right': df1, 'left': df2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent rhythms in triple meter (3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tm_pieces = note_list[mask & triple_meter]\n",
    "n_measures_per_tm_piece = tm_pieces.groupby(['id']).mn.nunique()\n",
    "osp_triple = note_list[mask & triple_meter].groupby(['id', 'mn']).apply(jh.os_pattern)\n",
    "osp_triple_r = note_list[mask & triple_meter & right].groupby(['id', 'mn']).apply(jh.os_pattern)\n",
    "osp_triple_l = note_list[mask & triple_meter & left].groupby(['id', 'mn']).apply(jh.os_pattern)\n",
    "df0 = jh.get_pattern_list(osp_triple, n_most_frequent=15, normalize=True)\n",
    "df1 = jh.get_pattern_list(osp_triple_r, n_most_frequent=15, normalize=True)\n",
    "df2 = jh.get_pattern_list(osp_triple_l, n_most_frequent=15, normalize=True)\n",
    "display_side_by_side({'overall': df0,'right': df1, 'left': df2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most stereotypical pieces in double meter\n",
    "To find the most rhythmically most stereotypical pieces, we take the most frequent onset pattern in the right hand, `TitiTiti` and the one in the left hand, `TaTa` and check which pieces have the highest percentage among all measures:\n",
    "\n",
    "| id  | TitiTiti_right | TaTa_left | piece                |\n",
    "|-----|----------------|-----------|----------------------|\n",
    "| 91  | 0.8125         | 0.8750    | D145ecossaise02.mscx |\n",
    "| 257 | 0.8750         | 0.8750    | D697ecossaise03.mscx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most stereotypical pieces in triple meter\n",
    "To find the most rhythmically most stereotypical pieces, we take the most frequent onset pattern in the right hand, `TitiTitiTiti` and the one in the left hand, `TaTaTa` and check which pieces have the highest percentage among all measures.\n",
    "\n",
    "| id  | TitiTitiTiti_right | TaTaTa_left | piece            |\n",
    "|-----|--------------------|-----------|--------------------|\n",
    "| 163 | 0.9583             | 0.8750    | D365walzer14.mscx  |\n",
    "| 269 | 0.9167             | 0.9167    | D734ländler08.mscx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating pattern detection with auto-correlation\n",
    "\n",
    "One common task in musicology is to identify _repeating patterns_ in a piece.\n",
    "\n",
    "For instance, a piece may be composed of 3 parts _A_, _B_, _C_, repeated as: _A-B-A-C_.\n",
    "\n",
    "Here we will focus on automating this detection process in our dataset of dance pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all the graphs for this part of the data story \n",
    "from tools import datastory_patterns as dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to identify a repeating part from a new part?\n",
    "\n",
    "The criterion to distinguish one part from another might be considered listener-dependent.\n",
    "One listener could for instance choose to identify parts as the overall _melody change_, but what makes for _enough_ melody change is left to arbitrary judgements.\n",
    "\n",
    "As an arguably more unanimous (and calculable) way to distiguish parts, we will consider that segment A repeats in segment B when a _sufficient fraction_ of the notes of A appear in B.\n",
    "Our first step to identify repeating patterns will then be to look for common notes for every two segments A and B.\n",
    "\n",
    "In classical music, a part is _necessarily_ composed of a whole number of metrics.\n",
    "To find repetitions, we will then have to compare every measure of a piece with each other measure of the same piece.\n",
    "\n",
    "The operations we will perform are called _auto-correlations_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of an auto-correlation for a musical piece\n",
    "\n",
    "Let a piece $A$ be a sequence of measures (in the musical sense) $a_x, x \\in \\left\\lbrace 0 ~..~ n \\right\\rbrace$.\n",
    "\n",
    "The auto-correlation of a **segment** $A_{\\alpha, \\beta} \\triangleq \\left[ a_\\alpha ~..~ a_\\beta \\right]$ of $A$ over $A$ is defined by:\n",
    "$$C_{A, \\alpha, \\beta}\\left( \\delta \\right) = \\sum\\limits_{i=\\alpha}^{\\beta}{a_i \\cdot a_{i + \\delta}}$$\n",
    "\n",
    "We then need to define a product function '$\\cdot$' that counts how many notes match in the two given measures $a_x$ and $a_y$.\n",
    "That is, the number of notes having same _pitches_ and same _onsets_ (i.e., start time relative to the beginning of the measure).\n",
    "When measure $a_i$ is outside the piece, it is considered empty: its product with any other measure is 0.\n",
    "There is a small peculiarity though: a sharp C is not equivalent to a flat D, although the same key would be pressed on a piano.\n",
    "Writing a flat D in a composition instead of a sharp C **may** reflect a global key change, which **may** be a hint for a section change.\n",
    "\n",
    "So we will consider two product functions: one matching _onset_ and _piano key_ (C♯4 matches D♭4, but C♯4 does not match C♯5), another matching _onset_ and _pitch class_ (C♯4 does not match D♭4, but C♯4 matches C♯5).\n",
    "The former function will be called the _key-product_, and the latter the _class-product_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using auto-correlation for initial section detection\n",
    "\n",
    "If a piece $A$ has repeating sections, we should expect to observe relatively high products $a_x \\cdot a_y$ for $x \\neq y$.\n",
    "\n",
    "Printing each pairwise product $a_x · a_y$ in a heatmap for the first piece (D41 menuett n°1), we can observe with respectively the _key-_ and _class-products_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.heatmap_piece1_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.heatmap_piece1_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first trivial observation is that these matrices are symmetrical, as the product functions are both commutative.\n",
    "Another observation is that the diagonal stands out. No surprise: every note of a measure is present in the same measure, hence a generally higher product on the diagonal corresponding to the number of notes in each measure.\n",
    "\n",
    "The heatmap produced show kind of \"supplementary diagonals\", which indicate part repetitions.\n",
    "Indeed: let suppose a piece is composed of two parts A-B-A, each part lasting 4 measures.\n",
    "Then one can expect these \"supplementary\" diagonals to start at measure index 8, marking the repetition of A.\n",
    "\n",
    "Repetitions can also be guessed by looking at the rows of a few measure.\n",
    "Taking for instance measure two, we see it repeats at 3 instances with one \"black\" spot.\n",
    "This tends to indicate a structure A-A-B-A.\n",
    "\n",
    "There is a problem though.\n",
    "Quite often measures do not repeat much within a part, especially the last measure of a part (take for instance measures 3, 7, 11, 16, but also measure 0 of D41 menuett n°1).\n",
    "This makes it hard to estimate part lengths.\n",
    "\n",
    "To overcome this issue, we will instead auto-correlate the whole piece with itself.\n",
    "The rationale is that when the offset $\\delta$ corresponds to a part offset (in our first example 8, and in the menuett above 4, 8, 12), a spike should appear as we auto-correlate a whole part and not measures alone.\n",
    "This approach is to work well when part lengths are of fixed size (or some are multiples of the other), which can be expected for many classical pieces.\n",
    "\n",
    "The autocorrelation of the first piece of our corpus, D41 menuett n°1, gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.autocor_piece1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From initial section detection to dance structure\n",
    "\n",
    "For sections of the same size, spikes correspond to part boundaries.\n",
    "In the example above, the part boundaries are at (0-4), (4-8), (8-12) and (12-16).\n",
    "To automate this detection, we need to write a filter detecting these spikes.\n",
    "We use a simple rolling window $w$ of size 3, and detect for which offsets $k$ we have: $w\\!\\left[k-1\\right] < w\\!\\left[k\\right]$ and $w\\!\\left[k\\right] \\ge w\\!\\left[k+1\\right]$\n",
    "\n",
    "Now that we have part boundaries, we still miss which parts correspond to which boundaries.\n",
    "To answer this question, each part boundary (0-4), (4-8), ... is auto-correlated (always for $\\delta = 0$) with each of the other part boundaries of the same size.\n",
    "This allows to identify where a part repeats, e.g. in D41 menuett n°1: (0-4) repeats in (4-8) and (12-16), as these measures have a _high-enough_, pairwise auto-correlation, but does not in (8-12).\n",
    "\n",
    "_High-enough_ is an arbitrary criteria.\n",
    "In our automated process, we use the notion of a _trigger_ (_threshold_ may have been more correct from an english standpoint):\n",
    "if the auto-correlation of detected parts X and Y divided by the number of notes in X is below the _trigger_ (a value between 0 and 1), the parts are considered disticts (i.e. Y is not X).\n",
    "The normalization is a primitive form of _regularization_, favoring repetition of _less complex_ measures.\n",
    "This is also an _interpretable_ parameter, as it is the minimal fraction of notes that must repeat (same onset and same key or pitch class) to consider a repetition.\n",
    "\n",
    "There is also a mechanism to merge adjacent parts for cosmetic reasons.\n",
    "For instance if a piece has a detected structure C-C-D-D-C-C, then the parts C-C and D-D can be rewritten as A = C-C and B = D-D, resulting in a visually more readable structure A-B-A.\n",
    "\n",
    "At this point, we have a function that translates a piece (a list of notes) to its structure (a list of letters) given a _trigger_ value.\n",
    "The higher the trigger, the more certain we are repetitions actually occurred.\n",
    "Now we have one more prior knownledge to add: most of the studied pieces are short and actually contain only 2 sections, or more rarely 3.\n",
    "Using this information, for each piece we will run the structure detection algorithm for $\\left[ 0.1 ~..~ 0.9 \\right]$ by steps of $0.1$, keeping the highest trigger that leads to selecting a structure with minimal number of different parts (and, of course, at least two parts).\n",
    "\n",
    "The results are laid in the table below.\n",
    "`HR` stands for the _key-product_ and `TR` for the _class-product_.\n",
    "The `confidence` column is only for readability purpose (it is immediately derived from the `trigger`, e.g. $0.4 \\le trigger < 0.6$ maps to \"presumably\"). A trigger of $0.$ means no structure found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp.structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying dance types\n",
    "\n",
    "This huge repertoire of piano pieces was intended for the private enjoyment of the Viennese bourgeoisie, whose social gatherings invariably involved music and, clearly, group dancing. Accordingly, each piece in the corpus bears as a title the name of one of the most common dance types of Schubert’s times. The title could not be assigned randomly, as the music had to match smoothly the common-sense expectations regarding the specific choreography that characterised each dance. Musicians and dancers were often amateurs, and yet, whenever the word “Walzer” or “Ländler” was heard everyone would also have known how the music would have sounded like, and  how to move on the dancing floor. However, it is by no means trivial to tell what the exact differences among dance types would be, and whether  these difference were encoded in the score or rather in the unspoken conventions of a specific social group striving to establish its status and identity in the powerful and dynamic environment of the early-19th-century Vienna. \n",
    "\n",
    "For instance, the Walzer and the Ländler could be experienced as the extremes of a continuum in a role-playing game across social classes, with the refined Walzer representing the high-class status eventually degenerating, but just for apotropaic fun, into the rural Ländler (Witzmann, 1976).\n",
    "\n",
    "In the following, we will attempt to single out musical features from the score that can be hypothesised to characterise different dance types, and assess to what extent they account for the original destination of the pieces as intended by the composer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Features\n",
    "\n",
    "Since there are only few instances of Galopp and Cotillon in the corpus, we will not include these dances in our investigation. Among the remaining dances, the Ecossaises are the only ones in duple meter (oom-pah-oom-pah rather than oom-pah-pah-oom-pah-pah): even the time-signature alone would provide perfect accuracy in recognising this dance type. Accordingly, we will focus on the non-trivial task of classifying the five triple-meter dance types: the French Menuet and Trio, and the German Ländler, Walzer and Deutscher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity\n",
    "\n",
    " Simplicity is the keyword for a popular musical product aimed at universally meeting the taste, and the keyboard skills, of the viennese bourgeoisie. A mass product for private consumption, somewhat similar to today’s playlists, these dances were to be enjoyed in rather informal settings within the familiar social atmosphere of the ballroom. All in all, the piano dance was not the ideal testing ground for compositional experimentalism. The entropy of the note distribution over the corpus reflects this feature. Compared to chamber arias and Lieder by Schubert himself and other earlier and later composers (Hasse, Mozart and Strauss), all somehow related to the Viennese environment, the dances show a more selective and hierarchically distributed usage of pitches (lower entropy).\n",
    "\n",
    "[Show here “entropy_comparisons” as interval plot]  [Snyder, J. L. (1990). Entropy as a Measure of Musical Style: The Influence of A Priori Assumptions, Music Theory Spectrum 12(1).]\n",
    "\n",
    "Among the various dance types, both Trios and Ländler have a significantly lower entropy on average than Deutscher, Walzer and Menuetts. In terms of pitch content, they are simpler than the other dance types.\n",
    "\n",
    "[Show here box plot ‘entropy’]\n",
    "\n",
    "What about the rhythm? The following plots show the entropy of the distribution of rhythmic durations and of rhythmic onsets: the higher the corresponding entropy, the more varied the notated and perceived rhythmic texture, respectively. In general, the “German” dances exhibit the tendency for a simpler texture than the “French” ones, maybe reflecting the stronger link to their folk origin.\n",
    "\n",
    "[Show here box plots ‘duration_entropy’ and ‘onset_entropy’, ideally with interactive menu]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intro\n",
    "\n",
    " A piece of tonal music is like a journey across different regions, each being characterised by specific sonorities, moods, colours. These features of a tonal region             arise as a consequence of the choice of notes and relationships among notes that the composer assembles in that particular spot in the music. In one word, a key: with this term, we refer to (1) a set of notes and (2) a hierarchy among them, where one note (the tonic) can be thought of as the center while all other notes have different functions with respect to the tonic itself. \n",
    "\n",
    "In each piece, one key is particularly important, as it marks the final goal and often also the starting point of the music: it is the global key of the piece. However, just as painters choose colours from their palette, composers can change the “colour” of the music by shifting from key to key as the piece unfolds. \n",
    "\n",
    "The most striking  distinction is between so-called major and minor keys, that roughly correspond to happy and melancholic moods respectively. Furthermore, with respect to the global key of a piece, each other major and minor key conveys different shades of these moods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methodology\n",
    "\n",
    "The musicological understanding of a piece relies on a detailed analysis of what is written in the score to infer the key that are encountered as it unfolds. However, to what extent does this score-based mode identification agree with the perceptual “feel” of a key? \n",
    "\n",
    "Extensive research has shown that Western listeners have consistent expectations on the fitness of individual notes into a key. For example, this plot (Krumhansl & Kessler, 1982) shows how much each one of the twelve notes is perceived as fitting into the Cmajor or Cminor keys: these are called the Cmajor and Cminor **key profiles**.\n",
    "\n",
    "[Show here the ‘maj_min_key_profiles' line plot]\n",
    "\n",
    "Any fragment of music consists of a **bag of notes**, i.e. the frequency distribution of notes occurring in the fragment itself. The correlation between the bag of notes and any individual key profile is a proxy to how perceptually close to that key the fragment of music is. Each fragment of music can closely match one key, i.e. sound decidedly *in* that key, based on the corresponding perceptual expectations, or it can be ambiguously equidistant to several keys. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking key\n",
    "\n",
    "It is possible to track the emotional journey of a dance by following the unfolding of keys in the piece, each key corresponding to a different musical colour or shade. Listen to the animated example, and then explore the emotional path of any dance of your choice by inspecting the corresponding graph. \n",
    "\n",
    "[Show here a video with animated plot and audio (maybe nr. 5?). Then, show static plots with interactive menu.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variety\n",
    "\n",
    "Let us look into some details. Many dances start and end in the same key, but this is by no means a necessity.\n",
    "\n",
    "[Show bar plot ’start_end_key']\n",
    "\n",
    "Dances have a twofold expressive purpose: being simple enough to be enjoyable without dedicated intellectual engagement, while at the same time materialising well-identified moods possibility taken to their extremes and contrasted with one another in sudden, although temporary, emotional clashes. As each key corresponds to an emotional region, how many keys does each dance cross during its journey? A plausible hypothesis is that certain dance-types are more likely to exhibit complex key trajectories than others.\n",
    "\n",
    "Indeed, more than half of the dances do not touch more than three keys, and unsurprisingly the rural Ländler are tendentially more likely to be monolithic in this respect compared to all other dance types.\n",
    "\n",
    "[Show here the stacked bar plot ’num_keys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode identification\n",
    "\n",
    "According to a musicological analysis, most dances are in the major mode, consistently with the enjoyable function of a dance. \n",
    "\n",
    "[Show here the stacked bar plot ‘dances_mode’ with color = gt_mode]\n",
    "\n",
    " The similarity with the major and minor profile determine the coordinates of a “mode space” where each dance occupies a point based on its incipit. \n",
    "\n",
    "[Show here the scatter plot ‘all_corr_first’]\n",
    "\n",
    "The diagonal of this plot sets predominantly positively and predominantly negatively valenced dances apart. The classification provided by this divider is indeed in good agreement with the musicological ground truth (Cohen’s Kappa = 0.847). The initial mood of a piece is what determines the musical character of the piece as a whole. \n",
    "\n",
    "In particular, we can also compute a coefficient of modal ambiguity for each dance: once again, Ländler stand out as being less likely to be more ambiguous compared to representatives of other dance types. \n",
    "\n",
    "[Show here the box plot ‘maj_min_first_abs’]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rhythmic patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Characteristic rhythmic patterns\n",
    "\n",
    "The individual rhythmic patterns singled out in Part I might contribute to characterise different dance types. In particular, the rhythmic texture of the left hand, which represents the metrical skeleton of the music and is less prone to the variety bias of a melodic line, might help the classification task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event density\n",
    "\n",
    "A surface-level characterisation of the texture of a dance is how \"crowded\" the music is: i.e., how many notes populate each time interval on average. \n",
    "\n",
    "[Show here box plot of 'event_density']\n",
    "\n",
    "All dances are somewhat similar in the overall density, but even more relevant for the auditory experience of music is the density of onsets of events, which marks the superficial rhythmic texture. French dances tend to be more dense in this respect.\n",
    "\n",
    "[Show here boxplot of 'onset_density']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downbeat accent\n",
    "\n",
    "Another potentially important feature for a dance is the relationship between the downbeat and the other beats of each bar, as this maps to the typical steps of the corresponding coreography. \n",
    "\n",
    "For example, it may be expected that a dance that is markedly \"in one\" (i.e., with one \"heavy\" step and two lighter ones) such as the spinning walzer might have a higher downbeat vs. offbeat density ratio compared to heavier dances that are markedly \"in three\" (e.g. the Ländler). However, this does not seem to be the case: Ländler have generally not lower downbeat vs. offbeat ratios with respect to Waltzer. This is biased, however, by a notational issue: in the well-known \"oom-pah-pah\" pattern of the Walzer, the first beat in the left hand is usually just one single note, while the second and third beats are chords; it is the performer, in these cases, that modulates the weight of the beats to convey the appropriate metrical feel, which is not reflected in the notation. These exceeds the scope of a score-based approach: especially in this case, music is a tool for social interaction, and much of the music-related knowledge is diffused in the social norms of the group rather than written down in the score.  \n",
    "\n",
    "However, compared to the German dances, French dances have heavier downbeats in terms of overall event density, considering both the events contained in the beats and those strictly happening *on* the beats.\n",
    "\n",
    "[Show here boxplot of 'ratio_downbeat_offbeat' and 'ratio_downbeat_offbeat_strictly']\n",
    "\n",
    "On the contrary, if we look at the ratio of onset densities between downbeats and offbeats, Menuets are significantly lower and Ländler asignificantly higher on average than other dances.\n",
    "\n",
    "[Show here boxplot of 'ratio_downbeat_offbeat_onset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristic intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registral accent\n",
    "\n",
    "A form of accent that is not reflected in the rhythmicality of the music is the *registral* accent, i.e. the abrupt change of height (register) within one voice. It may be hypothesised that this feeature may betray, on a notational level, the bar-by-bar flow typical of some dance types (see, e.g., the prototypical bass line in the example from Walzer D924 no. 1 above). In our case, the Ländler and the Walzer share the feature of having stronger registral accents on average than other dance types. \n",
    "\n",
    "[Show here boxplot interval_downbeat_offbeat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sixths and thirds\n",
    "\n",
    "As a final classification feature, we will consider the prevalence of certain pitch intervals in the various dances. Intervals of a sixth, in particular, are common to several"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "[Show here scatter plot ‘color = kmeans_label' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Although specific biases can be recognised for the different dance types with respect to all of the features discussed above, this may not be enough to classify individual dances. A SVM classifier performs in fact above chance-level in many cases, which is already a surprising outcome! \n",
    "\n",
    "[Show here confusion matrix 'cm']\n",
    "\n",
    "However, the selected features appear not to capture the differences among the three German dance types (Deutscher, Walzer, Ländler). Furthermore, Deutscher are viable labels for all other dance types. This might point to an interpretation of the “Deutscher” as a label employed by the composer to refer generally to a dance in the “German” style, but not necessarily fitting into the categories of a Ländler or a Walzer and rather somewhat closer to the default represented by the minuet and trio. Among the German dances, Ländler are the most peculiar: it is less likely for other dance types to be mistaken for Ländler. The different taste that is addressed by the Ländler genre, with its strong folk and rural references, is thus reflected in the compositional features we have analysed. \n",
    "    \n",
    "These issues notwithstanding, the feature are able to discriminate French from German dances with satisfactory effectiveness.\n",
    "\n",
    "[Show here confusion matrix ‘cm_national']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Analyzing a Corpus of Sheet Music",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
